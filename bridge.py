import asyncio
import json
import os
import base64
import time
import requests 
import shutil
import subprocess
from datetime import datetime
import traceback

import websockets
from pythonosc import udp_client
from openai import OpenAI
import fal_client

# ç§˜å¯†éµã®èª­ã¿è¾¼ã¿
import secret

# ==========================================
# è¨­å®šã‚¨ãƒªã‚¢
# ==========================================
WEBSOCKET_URL = os.getenv("KARMA_URL", "wss://karmic-identity.onrender.com/ws")  # æœ¬ç•ª
# WEBSOCKET_URL = "ws://localhost:8765"                      # â˜…ãƒ­ãƒ¼ã‚«ãƒ«

# (ãƒ•ã‚©ãƒ«ãƒ€ãŒãªã‘ã‚Œã°è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™)
base_path = os.path.join(os.path.expanduser("~"), "Ryoshian", "System", "renderData")
print(f"ğŸ“Œ base_path: {base_path}")
IMAGE_DIR = os.path.join(base_path, "Karma_Images")
VIDEO_DIR = os.path.join(base_path, "Karma_Videos")
TEXT_DIR = os.path.join(base_path, "Karma_Texts")

os.makedirs(IMAGE_DIR, exist_ok=True)
os.makedirs(VIDEO_DIR, exist_ok=True)
os.makedirs(TEXT_DIR, exist_ok=True)

# TouchDesignerè¨­å®š
OSC_IP = "127.0.0.1"
OSC_PORT = 9000

# ==========================================
# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ (ç¾å¤§æŒ‡å®šä»•æ§˜)
# ==========================================
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œå“ã€Karma Portraitã€ã®ãƒ–ãƒªãƒƒã‚¸ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸå›ç­”ã‹ã‚‰ã€Œæ¥­ï¼ˆã‚«ãƒ«ãƒï¼‰ã€ã‚’è§£æã—ã€TouchDesignerã¸æ¸¡ã™ãŸã‚ã®JSONã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€æœ€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘
- æ–‡å­—ã¯çµ¶å¯¾ã«ç”Ÿæˆã—ãªã„ï¼šè‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…ã« "no text" ã‚’å¿…ãšå…¥ã‚Œã€çœ‹æ¿ãƒ»å­—å¹•ãƒ»ãƒ­ã‚´ãƒ»é€ã‹ã—ãƒ»æ–‡å­—è¦ç´ ã‚’ä¸€åˆ‡å«ã‚ãªã„ã€‚
- äººé–“ã¯æ¥µåŠ›ç”Ÿæˆã—ãªã„ï¼šäººç‰©ãƒ»é¡”ãƒ»èº«ä½“è¡¨ç¾ã‚’é¿ã‘ã‚‹ã€‚ã©ã†ã—ã¦ã‚‚å¿…è¦ãªå ´åˆã®ã¿ã€å€‹æ€§ã®ãªã„é›†å›£ã¨ã—ã¦æå†™ã™ã‚‹ï¼ˆä¾‹ï¼šã‚¹ãƒ¼ãƒ„ã®ç¾¤è¡†ã€å¾Œã‚å§¿ã€ã‚·ãƒ«ã‚¨ãƒƒãƒˆã€é¡”ã¯æ˜ ã•ãšæ›–æ˜§ã€å€‹ä½“è­˜åˆ¥ä¸å¯ï¼‰ã€‚
- ã€æœ€å„ªå…ˆã€‘ã‚«ãƒ¡ãƒ©ãŒå‹•ãï¼šãƒ‰ãƒªãƒ¼ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆã€ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ç·©ã„ãƒãƒ³ãƒ‰ãƒ˜ãƒ«ãƒ‰ã®æ¼‚ã„ã€å¼·ã„ãƒ‘ãƒ©ãƒ©ãƒƒã‚¯ã‚¹ï¼ˆå‰æ™¯/ä¸­æ™¯/é æ™¯ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼‰ã‚’å¿…ãšå«ã‚ã‚‹ã€‚è¢«å†™ä½“ã®å‹•ãã‚ˆã‚Šã‚«ãƒ¡ãƒ©ç§»å‹•ã‚’å„ªå…ˆã€‚
- å‹•ãã¯ã€Œç”»è§’ç§»å‹•ãŒä¸»å½¹ã€ï¼šè¢«å†™ä½“ã®æ´¾æ‰‹ãªå‹•ãï¼ˆæ¿€ã—ã„æ³¢ãƒ»å¤§äººæ•°ã®æ¿€ã—ã„å‹•ãï¼‰ãŒå¼·ã™ãã¦ã‚«ãƒ¡ãƒ©ãŒæ­¢ã¾ã£ã¦è¦‹ãˆã‚‹å ´åˆã¯ã€è¢«å†™ä½“å´ã®å‹•ãã‚’æŠ‘ãˆã€å‰æ™¯ã®æµã‚Œï¼‹å¥¥è¡Œããƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ‘ãƒ©ãƒ©ãƒƒã‚¯ã‚¹ã‚’ä½œã‚‹ã€‚
- ç”»åƒç”Ÿæˆæ®µéšã§å¥¥è¡Œãã‚’ä½œã‚‹ï¼šæ¥µç«¯ãªå‰æ™¯ï¼ˆã‚«ãƒ¡ãƒ©ã«è¿‘ã„æ/è‘¦/çŸ³/æŸµ/æç¯ã®ãƒœã‚±ï¼‰ã€ä¸­æ™¯ã€é æ™¯ã‚’å¿…ãšç”¨æ„ã—ã€åºƒè§’å¯„ã‚Šã§ãƒ¬ã‚¤ãƒ¤ãƒ¼å·®ã‚’å¼·èª¿ã™ã‚‹ã€‚
- æ¶ç©ºã®å—å›½/åŒ—å›½/éƒ½å¸‚/ç”°èˆã¯ç¦æ­¢ï¼šå¿…ãšã€Œç¾å®Ÿã«å­˜åœ¨ã™ã‚‹å…·ä½“çš„ã‚¹ãƒãƒƒãƒˆï¼ˆåœ°å+å›½/éƒ½å¸‚åï¼‰ã€ã‚’é¸ã³ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ˜è¨˜ã™ã‚‹ã€‚
- æµ„åœŸã‚‰ã—ã„è³ªæ„Ÿã‚’é‡è¦–ï¼šæ¸…æ¾„ãƒ»ç™ºå…‰ãƒ»éœ§ãƒ»é‡‘ç®”/ç™½ç£/ä¹³ç™½ã®ã‚ˆã†ãªå…‰ã€é™è¬ã ãŒå¼·ã„ç”Ÿå‘½æ„Ÿï¼ˆæ¸…ã‚‰ã‹ãªç²’å­ãƒ»æŸ”ã‚‰ã‹ãªå…‰èŠ’ï¼‰ã‚’è¡¨ç¾ã€‚

ã€ãƒ†ã‚¤ã‚¹ãƒˆé¸æŠï¼ˆå›ç­”ã‹ã‚‰è‡ªå‹•ã§é¸ã¶ï¼‰ã€‘
- approach (æ—§reality_fantasyç›¸å½“) ãŒç¾å®Ÿå¯„ã‚Šï¼ˆ0ã€œ1ï¼‰â†’ `Hyper-realistic photography`ï¼ˆå†™å®Ÿ/é«˜ç²¾ç´°ï¼‰
- ä¸­é–“ï¼ˆ2ï¼‰â†’ `Cinematic CG`ï¼ˆå†™å®Ÿå¯„ã‚ŠCGï¼‰
- ç©ºæƒ³å¯„ã‚Šï¼ˆ3ã€œ4ï¼‰â†’ `Abstract generative`ï¼ˆæŠ½è±¡ãƒ™ãƒ¼ã‚¹ï¼‰

ã€ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³é¸æŠï¼ˆå…·ä½“ã‚¹ãƒãƒƒãƒˆã‚’å¿…ãš1ã¤ï¼‰ã€‘
- æ¶ç©ºã®å—å›½/åŒ—å›½/éƒ½å¸‚/ç”°èˆã¯ç¦æ­¢ï¼šå¿…ãšã€Œç¾å®Ÿã«å­˜åœ¨ã™ã‚‹å…·ä½“çš„ã‚¹ãƒãƒƒãƒˆï¼ˆåœ°å + éƒ½å¸‚/çœŒ/å›½ï¼‰ã€ã‚’é¸ã³ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ˜è¨˜ã™ã‚‹ã€‚
- åŒã˜å›ç­”ã®ä¸­ã§2æœ¬ç”Ÿæˆã™ã‚‹å ´åˆã¯ã€Variant A / Variant B ã§ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ¶å¯¾ã«è¢«ã‚‰ã›ãªã„ï¼ˆå›½/éƒ½é“åºœçœŒãƒ¬ãƒ™ãƒ«ã§ã‚‚åˆ¥ã«ã™ã‚‹ï¼‰ã€‚

â–¼éƒ½å¸‚å¯„ã‚Šï¼ˆenvironment_place ãŒ 0ã€œ1ï¼‰
- ä¾‹ï¼ˆæ—¥æœ¬ï¼‰: Shibuya Scramble Crossing, Tokyo / Ginza, Tokyo / Yokohama Minato Mirai, Kanagawa / Dotonbori, Osaka / Susukino, Sapporo, Hokkaido
- ä¾‹ï¼ˆæ±ã‚¢ã‚¸ã‚¢ï¼‰: Central, Hong Kong / Shinjuku Kabukicho, Tokyo / Taipei Ximending, Taipei / Gangnam, Seoul
- ä¾‹ï¼ˆä¸–ç•Œï¼‰: Times Square, New York / Piccadilly Circus, London / Place de la RÃ©publique, Paris / Marina Bay, Singapore

â–¼ç”°èˆãƒ»è‡ªç„¶å¯„ã‚Šï¼ˆenvironment_place ãŒ 3ã€œ4ï¼‰
- ä¾‹ï¼ˆæ—¥æœ¬ãƒ»åŒ—ï¼‰: Otaru Canal, Hokkaido / Lake Towada, Aomori / Shiretoko Peninsula, Hokkaido / Daisetsuzan National Park, Hokkaido
- ä¾‹ï¼ˆæ—¥æœ¬ãƒ»ä¸­éƒ¨ï¼‰: Shirakawa-go, Gifu / Kamikochi, Nagano / Kurobe Gorge, Toyama / Nakasendo (Magomeâ€“Tsumago), Naganoâ€“Gifu
- ä¾‹ï¼ˆæ—¥æœ¬ãƒ»è¥¿ï¼‰: Naoshima Island, Kagawa / Itsukushima Shrine (Miyajima), Hiroshima / Amanohashidate, Kyoto / Tottori Sand Dunes, Tottori

â–¼ä»æ•™æ€æƒ³ãƒ»å·¡ç¤¼/éœŠå ´ã®æ°—é…ï¼ˆæ—¥æœ¬ã«åˆã†è¦ç´ ï¼‰
- ä¾‹: Koyasan (Mount Koya), Wakayama / Kumano Kodo (Nakahechi Route), Wakayama / Eiheiji Temple, Fukui / Zenkoji Temple, Nagano
- ä¾‹: Nachi Falls, Wakayama / Mount Hiei (Enryakuji), Shiga / Dewa Sanzan (Mount Haguro), Yamagata / Osorezan, Aomori
- ä¾‹: Senso-ji, Asakusa, Tokyo / Ryoan-ji, Kyoto / Tofuku-ji, Kyoto / Todai-ji, Nara

â–¼æ²–ç¸„ï¼ˆå—å›½ã ãŒâ€œç¾å®Ÿã®å ´æ‰€â€ã§ã€éåº¦ã«ãƒªã‚¾ãƒ¼ãƒˆåŒ–ã—ãªã„ï¼‰
- ä¾‹: Shurijo Castle, Naha, Okinawa / Cape Manzamo, Onna, Okinawa / Taketomi Island, Okinawa / Iriomote Island mangrove forests, Okinawa / Ishigaki Kabira Bay, Okinawa

â–¼æ±å—ã‚¢ã‚¸ã‚¢ï¼ˆæ¹¿åº¦/é¦™/ç¥ˆã‚Šã®ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«ã«å¼·ã„ï¼‰
- ä¾‹: Angkor Wat, Siem Reap, Cambodia / Borobudur Temple, Central Java, Indonesia / Bagan Archaeological Zone, Myanmar
- ä¾‹: Luang Prabang temples, Laos / Chiang Mai Old City temples, Thailand / Ha Long Bay, Vietnam

â–¼åŒ—æ¬§ï¼ˆåŒ—ã®å…‰ãƒ»é›ªãƒ»é™ã‘ã•ã€ãƒŸãƒ‹ãƒãƒ«ãªæ§‹å›³ï¼‰
- ä¾‹: TromsÃ¸, Norway / Lofoten Islands, Norway / Reykjavik, Iceland / Thingvellir National Park, Iceland / Bergen Bryggen, Norway
- ä¾‹: Stockholm Gamla Stan, Sweden / Copenhagen Nyhavn, Denmark

â–¼è¦ç´ ï¼ˆReturnï¼‰ã¨ã®æ•´åˆ
- Return(0:Sea) ãªã‚‰æµ·ãƒ»é‹æ²³ãƒ»æ¹¾ãƒ»æ½®ã®ã‚ã‚‹å ´æ‰€ã‚’å„ªå…ˆï¼ˆãŸã ã—å‹•ãã¯æ°´é¢ã§ã¯ãªãã€Œã‚«ãƒ¡ãƒ©ç§»å‹•ï¼ˆãƒ‘ãƒ©ãƒ©ãƒƒã‚¯ã‚¹ï¼‰ã€ã‚’ä¸»å½¹ã«ã™ã‚‹ï¼‰
- Return(1:Soil) ãªã‚‰æ£®ãƒ»å±±ãƒ»å¯ºç¤¾ã®å‚é“ãƒ»çŸ³ç•³ãƒ»åœŸã®åŒ‚ã„ã®ã‚ã‚‹å ´æ‰€ã‚’å„ªå…ˆ
- Return(2:Sky) ãªã‚‰é«˜æ‰€ãƒ»åºƒã„ç©ºãƒ»é›²ãƒ»å…‰èŠ’ãƒ»æ¥µå…‰/æœç„¼ã‘/è–„æ˜ãªã©ã‚’å„ªå…ˆ

â–¼åŒ—/å—ï¼ˆheadingï¼‰ã«ã‚ˆã‚‹æ–¹å‘ã¥ã‘ï¼ˆãŸã ã—æ¶ç©ºã¯ç¦æ­¢ï¼‰
- åŒ—å¯„ã‚Šï¼ˆ0ã€œ1ï¼‰: åŒ—æµ·é“/æ±åŒ—/åŒ—æ¬§/é«˜ç·¯åº¦ï¼ˆé›ªãƒ»è–„æ˜ãƒ»å†·æ°—ï¼‰
- å—å¯„ã‚Šï¼ˆ3ã€œ4ï¼‰: æ²–ç¸„/æ±å—ã‚¢ã‚¸ã‚¢ï¼ˆæ¹¿åº¦ãƒ»æ¿ƒã„å½±ãƒ»æ°´é¢ã®åå°„ï¼‰

â€»åŒã˜å…¥åŠ›ã‹ã‚‰2æœ¬ç”Ÿæˆã™ã‚‹å ´åˆã¯ã€æ¬¡ã®ã€Œè¢«ã‚Šç¦æ­¢ã€ã‚’å¿…ãšå®ˆã‚‹:
- ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆéƒ½é“åºœçœŒ/å›½ãƒ¬ãƒ™ãƒ«ã§åˆ¥ï¼‰
- å­£ç¯€/å¤©å€™ï¼ˆä¾‹: é›ª vs é›¨ä¸ŠãŒã‚Šã€éœ§ vs å¼·ã„æ—¥å·®ã—ï¼‰
- æ™‚åˆ»ï¼ˆä¾‹: å¤œæ˜ã‘ vs å¤œã€å¤•æ™¯ vs æ›‡å¤©ï¼‰
- ä¸»ç´ æï¼ˆä¾‹: ç™½ç£/çŸ³/æœ¨/æ°´é¢/é‡‘ç®”ã®ã©ã‚Œã‚’å¼·èª¿ã™ã‚‹ã‹ï¼‰
- ã‚«ãƒ¡ãƒ©ã®å‹•ãï¼ˆãƒ‰ãƒªãƒ¼ä¸»ä½“ vs ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ä¸»ä½“ã€å‰æ™¯ã®æµã‚Œæ–¹ã‚’å¤‰ãˆã‚‹ï¼‰

ã€å‡ºåŠ›ã€‘
- visual_impression ã«ã¯ã€DALLÂ·E 3 ã«æ¸¡ã™ã€Œè‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’ç”Ÿæˆã™ã‚‹ã€‚
- è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯å¿…ãšæ¬¡ã‚’å«ã‚ã‚‹ï¼š
  - Vertical composition / Cinematic lighting
  - ã€æœ€å„ªå…ˆã€‘`Dynamic camera movement`ï¼ˆslow dolly-in/out, tracking shot, subtle handheld drift, strong parallax, foreground elements passing very close to camera, clear horizon shift / background parallaxï¼‰
  - ã€Œè¢«å†™ä½“ã®æ´¾æ‰‹ãªå‹•ãã€ã«é ¼ã‚‰ãªã„ï¼šæ³¢ãƒ»ç¾¤è¡†ãƒ»ç²’å­ãªã©ã®ãƒ­ãƒ¼ã‚«ãƒ«é‹å‹•ã¯æ§ãˆã‚ã«ã—ã€ç”»è§’ç§»å‹•ï¼ˆã‚«ãƒ¡ãƒ©ï¼‰ã§å‹•ãã‚’ä½œã‚‹
  - no text, no letters, no typography, no logo, no watermark, no subtitles
  - `no people`ï¼ˆäººç‰©ãŒå¿…è¦ãªã‚‰ `anonymous crowd silhouettes, no faces, no identifiable features`ï¼‰
  - å…·ä½“ã‚¹ãƒãƒƒãƒˆåï¼ˆåœ°å + éƒ½å¸‚/å›½ï¼‰
  - å¤©å€™ãƒ»æ°—å€™ãƒ»æ™‚é–“å¸¯ã‚’å…¥åŠ›èªå½™ã«åˆã‚ã›ã¦å¤‰ãˆã‚‹ï¼šclear / overcast / rain / snow / fog / humid haze / stormã€æ™‚é–“å¸¯ã¯ dawn / morning / daytime / sunset / night / midnight ã®ã„ãšã‚Œã‹ã‚’å¿…ãšæ˜è¨˜ã™ã‚‹
  - `Leica-like filmic color science`ï¼ˆsubtle film grain, gentle highlight roll-off, rich blacks, micro-contrast, natural yet cinematic tones; avoid oversaturated lookï¼‰
  
ã€å‡ºåŠ›JSONã€‘
{
  "variants": [
    {
      "variant_id": "A",
      "visual_impression": "English image prompt",
      "emotion_valance": -1.0ã€œ1.0,
      "emotion_arousal": 0.0ã€œ1.0,
      "karma_color": "#RRGGBB",
      "poetic_message": "30æ–‡å­—ä»¥å†…ã®è©©çš„ãªæ—¥æœ¬èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
      "location": "Selected real-world spot name",
      "style_mode": "Hyper-realistic photography | Cinematic CG | Abstract generative"
    },
    {
      "variant_id": "B",
      "visual_impression": "English image prompt (must be clearly different from A)",
      "emotion_valance": -1.0ã€œ1.0,
      "emotion_arousal": 0.0ã€œ1.0,
      "karma_color": "#RRGGBB",
      "poetic_message": "30æ–‡å­—ä»¥å†…ã®è©©çš„ãªæ—¥æœ¬èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸",
      "location": "Selected real-world spot name (must be different from A)",
      "style_mode": "Hyper-realistic photography | Cinematic CG | Abstract generative"
    }
  ]
}
"""

print(f"Bridge System Starting (v9.0 - Ryoshian New Form Edition)...")
print(f"ğŸ“‚ ç”»åƒä¿å­˜å…ˆ: {IMAGE_DIR}")
print(f"ğŸ“‚ å‹•ç”»ä¿å­˜å…ˆ: {VIDEO_DIR}")
print(f"ğŸ“‚ ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜å…ˆ: {TEXT_DIR}")

# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=secret.OPENAI_KEY)
os.environ["FAL_KEY"] = secret.FAL_KEY
osc_client = udp_client.SimpleUDPClient(OSC_IP, OSC_PORT)

# ==========================================
# 1. DALL-E 3 ç”»åƒç”Ÿæˆ
# ==========================================
def generate_base_image(prompt):
    print(f"ğŸ¨ [1/2] ãƒ™ãƒ¼ã‚¹ç”»åƒã‚’ç”Ÿæˆä¸­ (DALL-E 3)...")
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã®å®‰å…¨ç­–ã‚’çµåˆ
    safety_suffix = ", vertical composition, cinematic lighting, strong depth layers (foreground very close to lens, midground subject, distant background), wide-angle perspective (24mm), strong parallax, dynamic camera movement (slow dolly-in/out, tracking shot, subtle handheld drift), camera movement is the main motion (avoid relying only on subject motion), Leica-like filmic color science (subtle film grain, gentle highlight roll-off, rich blacks, micro-contrast, natural cinematic tones, avoid oversaturation), no text, no letters, no typography, no logo, no watermark, no subtitles, no people (or anonymous crowd silhouettes with no faces and no identifiable features only if absolutely necessary)"
    
    try:
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt + safety_suffix,
            size="1024x1792", 
            quality="standard",
            n=1,
        )
        image_url = response.data[0].url
        
        img_data = requests.get(image_url).content
        filename = f"gen_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}.jpg"
        save_path = os.path.join(IMAGE_DIR, filename)
        with open(save_path, 'wb') as f:
            f.write(img_data)
            
        print(f"âœ… ç”»åƒä¿å­˜å®Œäº†: {filename}")
        return os.path.abspath(save_path)
    except Exception as e:
        print(f"âŒ DALL-E ã‚¨ãƒ©ãƒ¼: {e}")
        return "none"

# ==========================================
# SVDç”¨: å…¥åŠ›ç”»åƒã‚’ 576x1024 ã«æ­£è¦åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
# SVDã¯ 576x1024 å‰æã§å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã“ã§æƒãˆã‚‹ã¨ã‚¯ãƒ­ãƒƒãƒ—/ä¼¸ã³ãŒæ¸›ã‚Šã‚„ã™ã„
# ==========================================
def prepare_svd_frame(image_path: str) -> str:
    try:
        # å…¥åŠ›ãŒæ—¢ã« 576x1024 ãªã‚‰ãã®ã¾ã¾
        try:
            from PIL import Image  # type: ignore
            with Image.open(image_path) as im:
                w, h = im.size
                if (w, h) == (576, 1024):
                    return image_path
        except Exception:
            # Pillow ãŒç„¡ã„/èª­ã‚ãªã„å ´åˆã¯ ffmpeg ã§è©¦ã™
            pass

        out_path = os.path.join(IMAGE_DIR, f"svd_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}.jpg")

        # ffmpeg ãŒä½¿ãˆã‚‹ãªã‚‰ãã‚Œã§ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆä¸€ç•ªå®‰å®šï¼‰
        if shutil.which("ffmpeg"):
            # 9:16ç¶­æŒã§ 576x1024 ã¸ï¼ˆä¸è¶³åˆ†ã¯ã‚»ãƒ³ã‚¿ãƒ¼ã§è»½ããƒˆãƒªãƒ ã•ã‚Œã‚‹ï¼‰
            cmd = [
                "ffmpeg", "-y", "-i", image_path,
                "-vf", "scale=576:1024:force_original_aspect_ratio=increase,crop=576:1024",
                "-q:v", "2",
                out_path,
            ]
            subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
            return os.path.abspath(out_path)

        # Pillow ãŒä½¿ãˆã‚‹ãªã‚‰ãã‚Œã§ãƒªã‚µã‚¤ã‚º
        try:
            from PIL import Image  # type: ignore
            with Image.open(image_path) as im:
                im = im.convert("RGB")
                # ã¾ãšé«˜ã•ã‚’1024ã«åˆã‚ã›ã€ä½™ã£ãŸå¹…ã‚’ä¸­å¤®ãƒˆãƒªãƒ 
                scale = 1024 / im.size[1]
                new_w = int(round(im.size[0] * scale))
                im2 = im.resize((new_w, 1024))
                if new_w > 576:
                    left = (new_w - 576) // 2
                    im2 = im2.crop((left, 0, left + 576, 1024))
                elif new_w < 576:
                    # è¶³ã‚Šãªã„åˆ†ã¯å·¦å³ã«é»’ãƒ‘ãƒƒãƒ‰ï¼ˆç¨€ï¼‰
                    pad = (576 - new_w) // 2
                    canvas = Image.new("RGB", (576, 1024), (0, 0, 0))
                    canvas.paste(im2, (pad, 0))
                    im2 = canvas
                im2.save(out_path, quality=95)
                return os.path.abspath(out_path)
        except Exception:
            return image_path

    except Exception:
        return image_path

# ==========================================
# é™æ­¢ç”»ã£ã½ã„å‹•ç”»ã®ç°¡æ˜“æ¤œå‡ºï¼ˆffmpeg ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
# fps=2ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã®md5ã‚’å–ã‚Šã€ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ãŒå°‘ãªã‘ã‚Œã°ã€Œã»ã¼é™æ­¢ã€ã¨ã¿ãªã™
# ==========================================
def looks_static_video(video_path: str) -> bool:
    try:
        if not shutil.which("ffmpeg"):
            return False

        cmd = [
            "ffmpeg", "-v", "error",
            "-i", video_path,
            "-vf", "fps=2",
            "-f", "framemd5",
            "-"
        ]
        p = subprocess.run(cmd, capture_output=True, text=True, check=True)
        hashes = []
        for line in p.stdout.splitlines():
            if not line or line.startswith("#"):
                continue
            parts = line.strip().split(",")
            if len(parts) >= 6:
                md5 = parts[-1].strip()
                if md5:
                    hashes.append(md5)
        if len(hashes) < 4:
            return False
        uniq = len(set(hashes))
        # ã»ã¼å…¨éƒ¨åŒã˜ãªã‚‰é™æ­¢ç”»ã®å¯èƒ½æ€§ãŒé«˜ã„
        return uniq <= 2
    except Exception:
        return False

# ==========================================
# 2. Fal.ai å‹•ç”»ç”Ÿæˆ (SVD)
# ==========================================
def generate_video(image_path, motion_bucket_id: int = 170, cond_aug: float = 0.05):
    print(f"ğŸ¬ [2/2] å‹•ç”»ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™ (Fal.ai)...")
    
    try:
        # SVDãŒå¾—æ„ãªè§£åƒåº¦(576x1024)ã«æƒãˆã‚‹ã¨ã€ä¸Šä¸‹/å·¦å³ã‚¯ãƒ­ãƒƒãƒ—ã®ãƒ–ãƒ¬ãŒæ¸›ã‚Šã‚„ã™ã„
        image_path = prepare_svd_frame(image_path)
        # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        print("   - ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
        url = fal_client.upload_file(image_path)
        
        # ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        print("   - ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡...")
        handler = fal_client.submit(
            "fal-ai/fast-svd",
            arguments={
                "image_url": url,
                "motion_bucket_id": motion_bucket_id,
                "cond_aug": cond_aug,
            }
        )

        result = handler.get()
        print(f"   - SVD params: motion_bucket_id={motion_bucket_id}, cond_aug={cond_aug}")
        
        if "video" in result and "url" in result["video"]:
            video_url = result["video"]["url"]
            print("âœ¨ ç”Ÿæˆå®Œäº†ï¼ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
            
            vid_data = requests.get(video_url).content
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            save_path = os.path.join(VIDEO_DIR, f"video_{timestamp}.mp4")
            
            with open(save_path, 'wb') as f:
                f.write(vid_data)
                
            print(f"âœ… ä¿å­˜å®Œäº†: {os.path.basename(save_path)}")
            saved = os.path.abspath(save_path)

            # ãŸã¾ã«é™æ­¢ç”»ã£ã½ã„å‹•ç”»ãŒå‡ºã‚‹ã®ã§ã€ã‚«ãƒ¡ãƒ©ç§»å‹•ã‚’å¼·ã‚ã¦1å›ã ã‘è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
            if looks_static_video(saved):
                print("âš ï¸ é™æ­¢ç”»ã£ã½ã„å‹•ç”»ã‚’æ¤œå‡ºã€‚ã‚«ãƒ¡ãƒ©ç§»å‹•ã‚’å¼·ã‚ã¦å†ç”Ÿæˆã—ã¾ã™...")
                try:
                    # å°‘ã—å¼·ã‚ã®è¨­å®šï¼ˆè¢«å†™ä½“é‹å‹•ã§ã¯ãªãç”»è§’ç§»å‹•ã‚’ç‹™ã†ï¼‰
                    return generate_video(image_path, motion_bucket_id=220, cond_aug=min(cond_aug + 0.02, 0.08))
                except Exception:
                    return saved

            return saved
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: çµæœç•°å¸¸ {result}")
            return "none"

    except Exception as e:
        print(f"âŒ å‹•ç”»ç”Ÿæˆä¾‹å¤–: {e}")
        return "none"

# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ•ãƒ­ãƒ¼
# ==========================================
async def process_data(data):
    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«åˆã‚ã›ã¦å±•é–‹
    identity = data.get('identity', {})
    conditions = data.get('conditions', {})
    adolescence = data.get('adolescence', {})
    adulthood = data.get('adulthood', {})
    philosophy = data.get('philosophy', {})
    afterlife = data.get('afterlife', {})
    legacy = data.get('legacy', {})

    print("\n===================================")
    print(f"ğŸ‘¤ å—ä¿¡: {identity.get('nickname')} ã•ã‚“ã®ãƒ‡ãƒ¼ã‚¿")

    # --- å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜ ---
    try:
        nickname = identity.get('nickname') or "anonymous"
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ãˆã‚‹ã‚ˆã†ç°¡æ˜“ã‚µãƒ‹ã‚¿ã‚¤ã‚º
        nickname_safe = "".join(c for c in str(nickname) if c.isalnum() or c in "-_" )
        if not nickname_safe:
            nickname_safe = "anonymous"

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        text_filename = f"input_{timestamp}_{nickname_safe}.txt"
        text_save_path = os.path.join(TEXT_DIR, text_filename)

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒå·¨å¤§ãªã®ã§ãƒ­ã‚°ã§ã¯ã‚µã‚¤ã‚ºæƒ…å ±ã«ç½®æ›
        data_for_log = dict(data)
        if "image_data" in data_for_log and data_for_log["image_data"]:
            data_for_log["image_data"] = f"<base64 image_data: {len(str(data_for_log['image_data']))} chars>"

        summary_text = f"""Karma Portrait / Input Log
Timestamp: {timestamp}
Nickname: {nickname}

[Identity]
- nickname: {identity.get('nickname')}
- age: {identity.get('age')}
- color: {identity.get('color')}

[Conditions]
- time: {conditions.get('time')}
- weather: {conditions.get('weather')}
- season: {conditions.get('season')}

[Adolescence]
- approach: {adolescence.get('approach')}
- place: {adolescence.get('environment_place')}
- sound: {adolescence.get('environment_sound')}
- sense: {adolescence.get('environment_sense')}
- scent: {adolescence.get('scent')}

[Adulthood]
- destination: {adulthood.get('destination')}
- wish: {adulthood.get('wish_direction')}
- drive: {adulthood.get('drive')}

[Philosophy]
- causality: {philosophy.get('causality')}
- compassion: {philosophy.get('compassion')}
- impermanence: {philosophy.get('impermanence')}
- life_death: {philosophy.get('life_death')}

[Afterlife]
- heading: {afterlife.get('heading')}
- returning: {afterlife.get('returning')}

[Legacy]
- keep: {legacy.get('keep')}
- likes: {legacy.get('likes')}
- avoids: {legacy.get('avoids')}

[Raw JSON (image_data omitted / summarized)]
{json.dumps(data_for_log, ensure_ascii=False, indent=2)}
"""

        with open(text_save_path, "w", encoding="utf-8") as f:
            f.write(summary_text)

        print(f"ğŸ“ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {os.path.basename(text_save_path)}")
    except Exception as e:
        print(f"âš ï¸ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    # --- ä¿å­˜ã“ã“ã¾ã§ ---

    saved_image_path = "none"
    has_user_image = False
    user_image_path = "none"
    
    # ã‚¹ãƒãƒ›ç”»åƒå‡¦ç†ï¼ˆä¿å­˜ã¯ã™ã‚‹ãŒã€å‹•ç”»ç”Ÿæˆã«ã¯ç›´æ¥ä½¿ã‚ãšGPTã®ãƒ’ãƒ³ãƒˆã«ã™ã‚‹ï¼‰
    if data.get("has_image") and data.get("image_data"):
        try:
            b64_str = data["image_data"]
            if "base64," in b64_str: b64_str = b64_str.split("base64,")[1]
            image_data = base64.b64decode(b64_str)
            filename = f"user_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}.jpg"
            saved_image_path = os.path.join(IMAGE_DIR, filename)
            with open(saved_image_path, "wb") as f:
                f.write(image_data)
            saved_image_path = os.path.abspath(saved_image_path)
            user_image_path = saved_image_path
            has_user_image = True
            print(f"ğŸ“· ã‚¹ãƒãƒ›ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ (è§£æç”¨)")
        except Exception as e:
            print(f"ç”»åƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    print("ğŸ§  GPT-4o è§£æä¸­...")
    
    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    user_input_text = f"""
    [Identity] Name:{identity.get('nickname')}, Age:{identity.get('age')}, Color:{identity.get('color')}
    [Conditions] Time(0-3):{conditions.get('time')}, Weather(0-4):{conditions.get('weather')}, Season(0-3):{conditions.get('season')}
    [Adolescence] Approach(0-4):{adolescence.get('approach')}, Place(0-4):{adolescence.get('environment_place')}, Sound(0-4):{adolescence.get('environment_sound')}, Sense(0-4):{adolescence.get('environment_sense')}, Scent(0-4):{adolescence.get('scent')}
    [Adulthood] Dest:{adulthood.get('destination')}, Wish(0-2):{adulthood.get('wish_direction')}, Drive(0-4):{adulthood.get('drive')}
    [Philosophy] Causal(0-4):{philosophy.get('causality')}, Compassion(0-4):{philosophy.get('compassion')}, Impermanence(0-4):{philosophy.get('impermanence')}, LifeDeath(0-1):{philosophy.get('life_death')}
    [Afterlife] Heading(0-4):{afterlife.get('heading')}, Returning(0-2):{afterlife.get('returning')}
    [Legacy] Keep:{legacy.get('keep')}, Likes:{legacy.get('likes')}, Avoids:{legacy.get('avoids')}
    """
    
    messages = [{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": user_input_text}]
    
    # ç”»åƒãŒã‚ã‚‹å ´åˆã€GPTã«è¦–è¦šæƒ…å ±ã¨ã—ã¦æ¸¡ã™
    if has_user_image:
        image_b64 = data.get("image_data", "")
        if "base64," in image_b64: image_b64 = image_b64.split("base64,", 1)[1]
        
        # Base64ãŒæ¥µç«¯ã«é•·ããªã„ã‹ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        if len(image_b64) < 2000000:
            messages[1]["content"] = [
                {"type": "text", "text": user_input_text},
                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
            ]
        else:
            print("âš ï¸ ç”»åƒã‚µã‚¤ã‚ºéå¤§ã®ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§è§£æã—ã¾ã™")

    try:
        response = await asyncio.to_thread(
            lambda: client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                response_format={"type": "json_object"}
            )
        )

        msg = response.choices[0].message
        content = getattr(msg, "content", None)
        
        if not content:
            raise ValueError("GPT returned empty content")

        result_json = json.loads(content)

        variants = []
        if isinstance(result_json, dict) and isinstance(result_json.get("variants"), list):
            variants = result_json["variants"]
        else:
            # æ—§å½¢å¼ï¼ˆå˜ç™ºï¼‰ã«ã‚‚äº’æ›
            variants = [result_json]

        # å¿…ãšæœ€å¤§2æœ¬ã«ã™ã‚‹
        variants = variants[:2]

        # ãƒ­ã‚°è¡¨ç¤º
        for i, v in enumerate(variants):
            vid = v.get("variant_id") or str(i)
            print(f"ğŸ’¬ ({vid}) ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {v.get('poetic_message')}")
            print(f"ğŸ“ ({vid}) ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: {v.get('location')}")

    except Exception as e:
        print(f"âš ï¸ GPTè§£æã‚¨ãƒ©ãƒ¼(ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨): {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®å®‰å…¨ç­–ï¼ˆæ­¢ã¾ã‚‰ãªã„ã‚ˆã†ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ã‚»ãƒƒãƒˆï¼‰
        result_json = {
            "variants": [
                {
                    "variant_id": "A",
                    "visual_impression": "Vertical abstract spiritual seascape, milky haze, soft light particles, strong parallax, slow dolly-in, no text, no people",
                    "emotion_valance": 0.0,
                    "emotion_arousal": 0.5,
                    "karma_color": "#EAF2FF",
                    "poetic_message": "å…‰ã®ç²’å­ãŒã€é™ã‹ã«é™ã‚Šæ³¨ã",
                    "location": "Naoshima Island, Kagawa, Japan",
                    "style_mode": "Abstract generative"
                },
                {
                    "variant_id": "B",
                    "visual_impression": "Vertical hyper-realistic photography of a quiet temple approach with wet stone path after rain, gentle mist, sacred god rays, strong parallax, tracking shot, Leica-like filmic color science, no text, no people",
                    "emotion_valance": 0.1,
                    "emotion_arousal": 0.45,
                    "karma_color": "#FFF3E6",
                    "poetic_message": "é›¨ã®åæ®‹ã‚ŠãŒã€é“ã‚’ç£¨ã",
                    "location": "Koyasan (Mount Koya), Wakayama, Japan",
                    "style_mode": "Hyper-realistic photography"
                }
            ]
        }
        variants = result_json["variants"]

    # === ç”»åƒ/å‹•ç”»ç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ2æœ¬ï¼‰ ===
    outputs = []
    for i, v in enumerate(variants):
        vid = v.get("variant_id") or str(i)
        prompt = v.get("visual_impression", "Vertical abstract spiritual landscape")
        print(f"ğŸ¨ ({vid}) ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰AIç”»åƒã‚’ç”Ÿæˆã—ã¾ã™...")

        video_input_path = await asyncio.to_thread(generate_base_image, prompt)

        # ä¸‡ãŒä¸€AIç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã€ã‚¹ãƒãƒ›ç”»åƒãŒã‚ã‚‹å ´åˆã®ã¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦ä½¿ç”¨
        if video_input_path == "none" and has_user_image:
            print(f"âš ï¸ ({vid}) AIç”Ÿæˆå¤±æ•—ã€‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦ã‚¹ãƒãƒ›ç”»åƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            video_input_path = user_image_path

        if video_input_path != "none":
            video_path = await asyncio.to_thread(generate_video, video_input_path)
            v["video_path"] = video_path
            v["variant_index"] = i
            outputs.append(v)
        else:
            print(f"âŒ ({vid}) ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€ã“ã®Variantã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

    # TouchDesignerã¸é€ä¿¡ï¼ˆäº’æ›: æ—§ /karmic_data ã¯Aã‚’é€ã‚‹ï¼‰
    if outputs:
        # æ—§äº’æ›: æœ€åˆã®1æœ¬ã‚’ /karmic_data
        osc_client.send_message("/karmic_data", json.dumps(outputs[0], ensure_ascii=False))

        # æ–°: 2æœ¬ã‚’å€‹åˆ¥ã‚¢ãƒ‰ãƒ¬ã‚¹ã§é€ã‚‹
        for out in outputs:
            idx = out.get("variant_index", 0)
            osc_client.send_message(f"/karmic_data/{idx}", json.dumps(out, ensure_ascii=False))

        # æ–°: ã¾ã¨ã‚ã¦é€ã‚‹ï¼ˆå¿…è¦ãªã‚‰TDå´ã§åˆ©ç”¨ï¼‰
        osc_client.send_message("/karmic_data_bundle", json.dumps({"variants": outputs}, ensure_ascii=False))

        print("ğŸ“¡ TouchDesignerã¸ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡ã—ã¾ã—ãŸï¼ˆ/karmic_data, /karmic_data/0.., /karmic_data_bundleï¼‰")
    else:
        print("âŒ ã™ã¹ã¦ã®Variantã§ç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€é€ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

# ==========================================
# å¾…æ©Ÿãƒ«ãƒ¼ãƒ— (ä¿®æ­£ç‰ˆ: æ¥ç¶šå¼·åŒ–)
# ==========================================
async def listen():
    custom_headers = {"User-Agent": "Bridge/1.0"}
    print(f"ğŸš€ ã‚µãƒ¼ãƒãƒ¼({WEBSOCKET_URL})ã«æ¥ç¶šã‚’é–‹å§‹ã—ã¾ã™...")
    
    while True:
        try:
            async with websockets.connect(
                WEBSOCKET_URL, 
                additional_headers=custom_headers, 
                ping_interval=None, 
                ping_timeout=None,
                close_timeout=100
            ) as websocket:
                print("âœ… æ¥ç¶šæˆåŠŸï¼å¾…æ©Ÿä¸­... (Ctrl+Cã§åœæ­¢)")
                
                while True:
                    try:
                        message = await websocket.recv()
                        data = json.loads(message)
                        if data.get("type") == "form_submission":
                            await process_data(data)
                    except websockets.exceptions.ConnectionClosed:
                        print("âš ï¸ åˆ‡æ–­ã•ã‚Œã¾ã—ãŸã€‚å†æ¥ç¶šã—ã¾ã™...")
                        break
                    except Exception as e:
                        print(f"âš ï¸ å—ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                        
        except Exception as e:
            print(f"âŒ æ¥ç¶šå¤±æ•—ï¼ˆ5ç§’å¾Œã«å†è©¦è¡Œï¼‰: {e}")
            await asyncio.sleep(5)

# ==========================================
# å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ (ã‚¨ãƒ©ãƒ¼æ™‚å¾…æ©Ÿæ©Ÿèƒ½ä»˜ã)
# ==========================================
if __name__ == "__main__":
    try:
        # ã“ã®è¡ŒãŒãªã„ã¨ãƒ«ãƒ¼ãƒ—ã«å…¥ã‚Šã¾ã›ã‚“
        asyncio.run(listen())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ãƒƒã‚·ãƒ¥: {e}")
        traceback.print_exc()
        print("\nENTERã‚­ãƒ¼ã‚’æŠ¼ã™ã¨çµ‚äº†ã—ã¾ã™...")
        input()